{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AOD-Net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMZ1yLrbe56J",
        "outputId": "c716f529-e2dd-42d8-cfb2-90e48ec1a603"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNr89akWvfXv"
      },
      "source": [
        "!mkdir samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMSTknBTPCle",
        "outputId": "f455752f-87ff-4c77-a7e4-37154edd1ef5"
      },
      "source": [
        "!pip install tensorboardX==1.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX==1.4\n",
            "  Downloading tensorboardX-1.4-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▉                           | 10 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 40 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 67 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.4) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.4) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.4) (3.17.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGmgnl67dF9c",
        "outputId": "ff51eda8-fea1-4716-a7d4-e6b097419183"
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import argparse\n",
        "import logging\n",
        "from functools import wraps\n",
        "\n",
        "FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "LEVEL = logging.DEBUG\n",
        "logging.basicConfig(format=FORMAT, level=LEVEL)\n",
        "log = logging.getLogger(__name__)\n",
        "log.info('Entered module: %s' % __name__)\n",
        "\n",
        "\n",
        "def logger(fn):\n",
        "    @wraps(fn)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        log = logging.getLogger(fn.__name__)\n",
        "        log.info('Start running %s' % fn.__name__)\n",
        "\n",
        "        out = fn(*args, **kwargs)\n",
        "\n",
        "        log.info('Done running %s' % fn.__name__)\n",
        "        # Return the return value\n",
        "        return out\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "def str2bool(v):\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "\n",
        "def weight_init(m):\n",
        "    if isinstance(m, torch.nn.Conv2d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            torch.nn.init.constant_(m.bias, 0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-20 09:37:49,384 - __main__ - INFO - Entered module: __main__\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHjhtJPudZgq"
      },
      "source": [
        "# from utils import str2bool\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--ori_data_path', type=str, default='ori',  help='Origin image path')\n",
        "parser.add_argument('--haze_data_path', type=str, default='haze',  help='Haze image path')\n",
        "parser.add_argument('--val_ori_data_path', type=str, default='val_ori',  help='Validation origin image path')\n",
        "parser.add_argument('--val_haze_data_path', type=str, default='val_haze',  help='Validation haze image path')\n",
        "parser.add_argument('--sample_output_folder', type=str, default='samples',  help='Validation haze image path')\n",
        "parser.add_argument('--use_gpu', type=str2bool, default=True, help='Use GPU')\n",
        "parser.add_argument('--gpu', type=int, default=-1, help='GPU id')\n",
        "parser.add_argument('--lr', type=float, default=1e-4, help='Learning Rate. Default=1e-4')\n",
        "parser.add_argument('--num_workers', type=int, default=4, help='Number of threads for data loader, for window set to 0')\n",
        "parser.add_argument('--print_gap', type=int, default=50, help='number of batches to print average loss ')\n",
        "parser.add_argument('--batch_size', type=int, default=16, help='Training batch size')\n",
        "parser.add_argument('--val_batch_size', type=int, default=16, help='Validation batch size')\n",
        "parser.add_argument('--epochs', type=int, default=10, help='number of epochs for training')\n",
        "parser.add_argument('--model_dir', type=str, default='./model')\n",
        "parser.add_argument('--log_dir', type=str, default='./log')\n",
        "parser.add_argument('--ckpt', type=str, default='./model/nets/net_1.pkl')\n",
        "parser.add_argument('--net_name', type=str, default='nets')\n",
        "parser.add_argument('--weight_decay', type=float, default=0.0001)\n",
        "parser.add_argument('--grad_clip_norm', type=float, default=0.1)\n",
        "\n",
        "\n",
        "def get_config():\n",
        "    config, unparsed = parser.parse_known_args()\n",
        "    return config, unparsed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuMapFzndjt2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class AODnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AODnet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=6, out_channels=3, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv4 = nn.Conv2d(in_channels=6, out_channels=3, kernel_size=7, stride=1, padding=3)\n",
        "        self.conv5 = nn.Conv2d(in_channels=12, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
        "        self.b = 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = F.relu(self.conv1(x))\n",
        "        x2 = F.relu(self.conv2(x1))\n",
        "        cat1 = torch.cat((x1, x2), 1)\n",
        "        x3 = F.relu(self.conv3(cat1))\n",
        "        cat2 = torch.cat((x2, x3), 1)\n",
        "        x4 = F.relu(self.conv4(cat2))\n",
        "        cat3 = torch.cat((x1, x2, x3, x4), 1)\n",
        "        k = F.relu(self.conv5(cat3))\n",
        "\n",
        "        if k.size() != x.size():\n",
        "            raise Exception(\"k, haze image are different size!\")\n",
        "\n",
        "        output = k * x - k + self.b\n",
        "        return F.relu(output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n73mY926doeV"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import glob\n",
        "import random\n",
        "\n",
        "\n",
        "class HazeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, ori_root, haze_root, transforms):\n",
        "        self.haze_root = haze_root\n",
        "        self.ori_root = ori_root\n",
        "        self.image_name_list = glob.glob(os.path.join(self.haze_root, '*.jpg'))\n",
        "        self.matching_dict = {}\n",
        "        self.file_list = []\n",
        "        self.get_image_pair_list()\n",
        "        self.transforms = transforms\n",
        "        print(\"Total data examples:\", len(self.file_list))\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"\n",
        "        :param item:\n",
        "        :return: haze_img, ori_img\n",
        "        \"\"\"\n",
        "        ori_image_name, haze_image_name = self.file_list[item]\n",
        "        ori_image = self.transforms(Image.open(ori_image_name))\n",
        "        haze_image = self.transforms(Image.open(haze_image_name))\n",
        "        return ori_image, haze_image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def get_image_pair_list(self):\n",
        "        for image in self.image_name_list:\n",
        "            image = image.split(\"/\")[-1]\n",
        "            key = image.split(\"_\")[0] + \"_\" + image.split(\"_\")[1] + \".jpg\"\n",
        "            if key in self.matching_dict.keys():\n",
        "                self.matching_dict[key].append(image)\n",
        "            else:\n",
        "                self.matching_dict[key] = []\n",
        "                self.matching_dict[key].append(image)\n",
        "\n",
        "        for key in list(self.matching_dict.keys()):\n",
        "            for hazy_image in self.matching_dict[key]:\n",
        "                self.file_list.append([os.path.join(self.ori_root, key), os.path.join(self.haze_root, hazy_image)])\n",
        "\n",
        "        random.shuffle(self.file_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUob42UVgUSL"
      },
      "source": [
        "import argparse\n",
        "# argument parser instead of command line\n",
        "args = argparse.Namespace(\n",
        "                epochs = 10,\n",
        "                net_name = 'aod-xavier',\n",
        "                lr = 1e-4,\n",
        "                use_gpu = True,\n",
        "                gpu = 1, #3\n",
        "                ori_data_path = '/content/drive/MyDrive/AOD/original_image/image/',\n",
        "                haze_data_path = '/content/drive/MyDrive/AOD/training_images/data/',\n",
        "                val_ori_data_path = '/content/drive/MyDrive/AOD/original_image/image/',\n",
        "                val_haze_data_path = '/content/drive/MyDrive/AOD/training_images/data/',\n",
        "                num_workers = 2,\n",
        "                batch_size = 8,\n",
        "                val_batch_size = 16,\n",
        "                print_gap = 500,\n",
        "                model_dir = '/content/drive/MyDrive/AOD/models/',\n",
        "                log_dir = '/content/drive/MyDrive/AOD/logs',\n",
        "                sample_output_folder = '/content/samples',\n",
        "                weight_decay = 0.0001,\n",
        "                grad_clip_norm = 0.1,\n",
        "                pretrain = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E53PpFpfalaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfd335c-f63b-4123-fd8a-f5119ffe7b4f"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.backends.cudnn\n",
        "import torch.nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "# from utils import logger, weight_init\n",
        "# from config import get_config\n",
        "# from model import AODnet\n",
        "# from data import HazeDataset\n",
        "pretrain_directory = '/content/drive/MyDrive/AOD/models/aod-xavier/AOD_1.pkl'\n",
        "\n",
        "@logger\n",
        "def load_data(cfg):\n",
        "    data_transform = transforms.Compose([\n",
        "        transforms.Resize([480, 640]),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    train_haze_dataset = HazeDataset(cfg.ori_data_path, cfg.haze_data_path, data_transform)\n",
        "    train_loader = torch.utils.data.DataLoader(train_haze_dataset, batch_size=cfg.batch_size, shuffle=True,\n",
        "                                               num_workers=cfg.num_workers, drop_last=True, pin_memory=True)\n",
        "\n",
        "    val_haze_dataset = HazeDataset(cfg.val_ori_data_path, cfg.val_haze_data_path, data_transform)\n",
        "    val_loader = torch.utils.data.DataLoader(val_haze_dataset, batch_size=cfg.val_batch_size, shuffle=False,\n",
        "                                             num_workers=cfg.num_workers, drop_last=True, pin_memory=True)\n",
        "\n",
        "    return train_loader, len(train_loader), val_loader, len(val_loader)\n",
        "\n",
        "\n",
        "@logger\n",
        "def save_model(epoch, path, net, optimizer, net_name):\n",
        "    if not os.path.exists(os.path.join(path, net_name)):\n",
        "        os.mkdir(os.path.join(path, net_name))\n",
        "    torch.save({'epoch': epoch, 'state_dict': net.state_dict(), 'optimizer': optimizer.state_dict()},\n",
        "               f=os.path.join(path, net_name, '{}_{}.pkl'.format('AOD', epoch)))\n",
        "\n",
        "\n",
        "@logger\n",
        "def load_network(device):\n",
        "    net = AODnet().to(device)\n",
        "    net.apply(weight_init)\n",
        "    return net\n",
        "\n",
        "@logger\n",
        "def load_pretrain_network(device):\n",
        "    net = AODnet().to(device)\n",
        "    net.load_state_dict(torch.load(pretrain_directory)['state_dict'])\n",
        "    return net\n",
        "\n",
        "@logger\n",
        "def load_optimizer(net, cfg):\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "@logger\n",
        "def loss_func(device):\n",
        "    criterion = torch.nn.MSELoss().to(device)\n",
        "    return criterion\n",
        "\n",
        "\n",
        "@logger\n",
        "def load_summaries(cfg):\n",
        "    summary = SummaryWriter(log_dir=os.path.join(cfg.log_dir, cfg.net_name), comment='')\n",
        "    return summary\n",
        "\n",
        "\n",
        "def main(cfg):\n",
        "    # -------------------------------------------------------------------\n",
        "    # basic config\n",
        "    print(cfg)\n",
        "    if cfg.gpu > -1:\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = str(cfg.gpu)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    # -------------------------------------------------------------------\n",
        "    # load summaries\n",
        "    summary = load_summaries(cfg)\n",
        "    # -------------------------------------------------------------------\n",
        "    # load data\n",
        "    train_loader, train_number, val_loader, val_number = load_data(cfg)\n",
        "    # -------------------------------------------------------------------\n",
        "    # load loss\n",
        "    criterion = loss_func(device)\n",
        "    # -------------------------------------------------------------------\n",
        "    # load network\n",
        "    if cfg.pretrain == True:\n",
        "      network = load_pretrain_network(device)\n",
        "    else:\n",
        "      network = load_network(device)\n",
        "    # -------------------------------------------------------------------\n",
        "    # load optimizer\n",
        "    optimizer = load_optimizer(network, cfg)\n",
        "    # -------------------------------------------------------------------\n",
        "    # start train\n",
        "    print('Start train')\n",
        "    print(cfg.pretrain)\n",
        "    network.train()\n",
        "    if cfg.pretrain == True:\n",
        "      current_epoch = pretrain_directory.split('_')\n",
        "      current_epoch = current_epoch[1].split('.')\n",
        "      current_epoch = int (current_epoch[0])+1\n",
        "      for epoch in range(current_epoch,cfg.epochs):\n",
        "        for step, (ori_image, haze_image) in enumerate(train_loader):\n",
        "            count = epoch * train_number + (step + 1)\n",
        "            ori_image, haze_image = ori_image.to(device), haze_image.to(device)\n",
        "            dehaze_image = network(haze_image)\n",
        "            loss = criterion(dehaze_image, ori_image)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(network.parameters(), cfg.grad_clip_norm)\n",
        "            optimizer.step()\n",
        "            summary.add_scalar('loss', loss.item(), count)\n",
        "            if step % cfg.print_gap == 0:\n",
        "                summary.add_image('DeHaze_Images', make_grid(dehaze_image[:4].data, normalize=True, scale_each=True),\n",
        "                                  count)\n",
        "                summary.add_image('Haze_Images', make_grid(haze_image[:4].data, normalize=True, scale_each=True), count)\n",
        "                summary.add_image('Origin_Images', make_grid(ori_image[:4].data, normalize=True, scale_each=True),\n",
        "                                  count)\n",
        "            print('Epoch: {}/{}  |  Step: {}/{}  |  lr: {:.6f}  | Loss: {:.6f}'\n",
        "                  .format(epoch + 1, cfg.epochs, step + 1, train_number,\n",
        "                          optimizer.param_groups[0]['lr'], loss.item()))\n",
        "        # -------------------------------------------------------------------\n",
        "        # start validation\n",
        "        print('Epoch: {}/{} | Validation Model Saving Images'.format(epoch + 1, cfg.epochs))\n",
        "        network.eval()\n",
        "        for step, (ori_image, haze_image) in enumerate(val_loader):\n",
        "            if step > 10:   # only save image 10 times\n",
        "                break\n",
        "            ori_image, haze_image = ori_image.to(device), haze_image.to(device)\n",
        "            dehaze_image = network(haze_image)\n",
        "            torchvision.utils.save_image(\n",
        "                torchvision.utils.make_grid(torch.cat((haze_image, dehaze_image, ori_image), 0),\n",
        "                                            nrow=ori_image.shape[0]),\n",
        "                os.path.join(cfg.sample_output_folder, '{}_{}.jpg'.format(epoch + 1, step)))\n",
        "        network.train()\n",
        "        # -------------------------------------------------------------------\n",
        "        # save per epochs model\n",
        "        save_model(epoch, cfg.model_dir, network, optimizer, cfg.net_name)\n",
        "        # -------------------------------------------------------------------\n",
        "         # train finish\n",
        "        summary.close()\n",
        "    else:\n",
        "      for epoch in range(cfg.epochs):\n",
        "          for step, (ori_image, haze_image) in enumerate(train_loader):\n",
        "              count = epoch * train_number + (step + 1)\n",
        "              ori_image, haze_image = ori_image.to(device), haze_image.to(device)\n",
        "              dehaze_image = network(haze_image)\n",
        "              loss = criterion(dehaze_image, ori_image)\n",
        "              optimizer.zero_grad()\n",
        "              loss.backward()\n",
        "              torch.nn.utils.clip_grad_norm_(network.parameters(), cfg.grad_clip_norm)\n",
        "              optimizer.step()\n",
        "              summary.add_scalar('loss', loss.item(), count)\n",
        "              if step % cfg.print_gap == 0:\n",
        "                  summary.add_image('DeHaze_Images', make_grid(dehaze_image[:4].data, normalize=True, scale_each=True),\n",
        "                                    count)\n",
        "                  summary.add_image('Haze_Images', make_grid(haze_image[:4].data, normalize=True, scale_each=True), count)\n",
        "                  summary.add_image('Origin_Images', make_grid(ori_image[:4].data, normalize=True, scale_each=True),\n",
        "                                    count)\n",
        "              print('Epoch: {}/{}  |  Step: {}/{}  |  lr: {:.6f}  | Loss: {:.6f}'\n",
        "                    .format(epoch + 1, cfg.epochs, step + 1, train_number,\n",
        "                            optimizer.param_groups[0]['lr'], loss.item()))\n",
        "          # -------------------------------------------------------------------\n",
        "          # start validation\n",
        "          print('Epoch: {}/{} | Validation Model Saving Images'.format(epoch + 1, cfg.epochs))\n",
        "          network.eval()\n",
        "          for step, (ori_image, haze_image) in enumerate(val_loader):\n",
        "              if step > 10:   # only save image 10 times\n",
        "                  break\n",
        "              ori_image, haze_image = ori_image.to(device), haze_image.to(device)\n",
        "              dehaze_image = network(haze_image)\n",
        "              torchvision.utils.save_image(\n",
        "                  torchvision.utils.make_grid(torch.cat((haze_image, dehaze_image, ori_image), 0),\n",
        "                                              nrow=ori_image.shape[0]),\n",
        "                  os.path.join(cfg.sample_output_folder, '{}_{}.jpg'.format(epoch + 1, step)))\n",
        "          network.train()\n",
        "          # -------------------------------------------------------------------\n",
        "          # save per epochs model\n",
        "          save_model(epoch, cfg.model_dir, network, optimizer, cfg.net_name)\n",
        "      # -------------------------------------------------------------------\n",
        "      # train finish\n",
        "      summary.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # config_args, unparsed_args = args.\n",
        "    main(args)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-20 09:37:55,175 - load_summaries - INFO - Start running load_summaries\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=8, epochs=10, gpu=1, grad_clip_norm=0.1, haze_data_path='/content/drive/MyDrive/AOD/training_images/data/', log_dir='/content/drive/MyDrive/AOD/logs', lr=0.0001, model_dir='/content/drive/MyDrive/AOD/models/', net_name='aod-xavier', num_workers=2, ori_data_path='/content/drive/MyDrive/AOD/original_image/image/', pretrain=False, print_gap=500, sample_output_folder='/content/samples', use_gpu=True, val_batch_size=16, val_haze_data_path='/content/drive/MyDrive/AOD/training_images/data/', val_ori_data_path='/content/drive/MyDrive/AOD/original_image/image/', weight_decay=0.0001)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-20 09:37:55,627 - root - INFO - Generating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
            "2021-08-20 09:37:55,658 - root - INFO - Generating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
            "2021-08-20 09:37:55,812 - load_summaries - INFO - Done running load_summaries\n",
            "2021-08-20 09:37:55,814 - load_data - INFO - Start running load_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2an_fm3qh29q",
        "outputId": "fd854cf7-e98d-4907-8b5e-a65859b675b8"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nn8YQuEhh-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e9b21ea-caca-49e1-ed4a-671fc8128f67"
      },
      "source": [
        "# # net = load_network(device)\n",
        "\n",
        "# net = AODnet().to(device)\n",
        "# net1= net.load_state_dict(torch.load('/content/AOD-Net-PyTorch/aod-xavier/AOD_0.pkl')['state_dict'])\n",
        "pretrain_directory = '/content/drive/MyDrive/AOD/models/aod-xavier/AOD_5.pkl'\n",
        "@logger\n",
        "def load_pretrain_network(device):\n",
        "    net = AODnet().to(device)\n",
        "    net.load_state_dict(torch.load(pretrain_directory)['state_dict'])\n",
        "    return net\n",
        "network = load_pretrain_network(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-12 11:10:16,962 - load_pretrain_network - INFO - Start running load_pretrain_network\n",
            "2021-08-12 11:10:29,442 - load_pretrain_network - INFO - Done running load_pretrain_network\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE1Ja0g8jwzk"
      },
      "source": [
        "import torchvision\n",
        "def make_test_data(img_path_list, device):\n",
        "    data_transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize([480, 640]),\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ])\n",
        "    imgs = []\n",
        "    for img_path in img_path_list:\n",
        "        x = data_transform(Image.open(img_path)).unsqueeze(0)\n",
        "        x = x.to(device)\n",
        "        imgs.append(x)\n",
        "    return imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drqAH7gFodlP"
      },
      "source": [
        "!mkdir results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epO4QBXHh5Xv"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# image = make_test_data(glob.glob('/content/drive/MyDrive/AOD/test/*.jpg'),device)\n",
        "# image = make_test_data(glob.glob('/content/drive/MyDrive/AOD/fog/*.jpg'),device)\n",
        "image = make_test_data(glob.glob('/content/drive/MyDrive/pku-autonomous-driving/train_images/ID_0a3c2c009.jpg'),device)\n",
        "# image = make_test_data(glob.glob('/content/drive/MyDrive/AOD/original_image/image/*.jpg'),device)\n",
        "network.eval()\n",
        "for y,i in enumerate(image):\n",
        "  try:\n",
        "    dehaze_image = network(i)\n",
        "    #********************** Uncomment to get side by side comparison *******************************\n",
        "    # torchvision.utils.save_image(torch.cat((i, dehaze_image), 0), \"results/res\"+str (y)+\".jpg\")\n",
        "\n",
        "    #********************** Uncomment to get only dehazed images ***********************************\n",
        "    torchvision.utils.save_image(i, \"results/original\"+str (y)+\".jpg\")\n",
        "    torchvision.utils.save_image(dehaze_image, \"results/dehazed\"+str (y)+\".jpg\")\n",
        "  except:\n",
        "    print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Iefwhs6T31m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd2ad264-3342-45ba-a332-68b2264ce46b"
      },
      "source": [
        "import os\n",
        "for subdir, dirs, files in os.walk('/content/results'):\n",
        "    print(len(files))\n",
        "    total_no_images = len(files)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yX1DW1-Q8Z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4e63fa-9cf2-4ebc-ec54-0282e01674c8"
      },
      "source": [
        "# from skimage.measure import structural_similarity as ssim\n",
        "from skimage import measure\n",
        "import cv2\n",
        "ssim = 0\n",
        "for i in range(int ((total_no_images/2)+1)):\n",
        "  try:\n",
        "    print(i)\n",
        "    original = np.array(Image.open('/content/results/original'+str (i)+'.jpg'))\n",
        "    dehazed = np.array(Image.open('/content/results/dehazed'+str (i)+'.jpg'))\n",
        "    ssim += measure.compare_ssim(original,dehazed, multichannel=True)\n",
        "  except:\n",
        "    print(i)\n",
        "print(ssim/(total_no_images/2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "0.7711632701007402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffk4jogl61mo",
        "outputId": "32d4affa-0a21-4e67-ae82-1f4e6fb065d4"
      },
      "source": [
        "original = np.array(Image.open('/content/results/original0.jpg'))\n",
        "dehazed = np.array(Image.open('/content/results/dehazed0.jpg'))\n",
        "# plt.imshow(dehazed)\n",
        "measure.compare_ssim(original,dehazed, multichannel=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8481487202536986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDNhFeywTm0J"
      },
      "source": [
        "from math import log10, sqrt\n",
        "def PSNR(original, compressed):\n",
        "    mse = np.mean((original - compressed) ** 2)\n",
        "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
        "                  # Therefore PSNR have no importance.\n",
        "        return 100\n",
        "    max_pixel = 255.0\n",
        "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
        "    return psnr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sElmO8EKTtIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3858296-7185-461e-c8e1-78691fbf3ede"
      },
      "source": [
        "psnr = 0\n",
        "for i in range(int ((total_no_images/2)+1)):\n",
        "  try:\n",
        "    print(i)\n",
        "    original = np.array(Image.open('/content/results/original'+str (i)+'.jpg'))\n",
        "    dehazed = np.array(Image.open('/content/results/dehazed'+str (i)+'.jpg'))\n",
        "    psnr += PSNR(original,dehazed)\n",
        "  except:\n",
        "    print(i)\n",
        "print(psnr/(total_no_images/2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "28.028685715982526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-aCPD6jZDqd",
        "outputId": "7a58531b-e1c9-4158-d688-5853985b8bb2"
      },
      "source": [
        "original = np.array(Image.open('/content/results/original0.jpg'))\n",
        "dehazed = np.array(Image.open('/content/results/dehazed0'+'.jpg'))\n",
        "psnr = PSNR(original,dehazed)\n",
        "print(psnr)\n",
        "from skimage import measure\n",
        "ssim = measure.compare_ssim(original,dehazed, multichannel=True)\n",
        "print(ssim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27.728293393725476\n",
            "0.8481487202536986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNsHJkY9C5oh",
        "outputId": "d4460dcc-8033-4725-a834-b74c458be8c9"
      },
      "source": [
        "mse = 0\n",
        "for i in range(int ((total_no_images/2)+1)):\n",
        "  try:\n",
        "    print(i)\n",
        "    original = np.array(Image.open('/content/results/original'+str (i)+'.jpg'))\n",
        "    dehazed = np.array(Image.open('/content/results/dehazed'+str (i)+'.jpg'))\n",
        "    mse += np.mean((original - dehazed) ** 2)\n",
        "  except:\n",
        "    print(i)\n",
        "print(mse/(total_no_images/2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "103.29386470526764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyvaOH21ixIq",
        "outputId": "c4480665-1dda-43de-ec4e-4375285a86cc"
      },
      "source": [
        "mse = np.mean((original - dehazed) ** 2)\n",
        "print(mse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "109.71121419270834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd4eNoZvMoGF"
      },
      "source": [
        "plt.imshow(original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOpI5ozOSwCI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "e3b929ac-a732-4738-9724-7f7e8711144e"
      },
      "source": [
        "plt.imshow(dehazed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2856188e67d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdehazed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_1VwLDG2oAS"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive('results', 'zip', '/content/results')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}